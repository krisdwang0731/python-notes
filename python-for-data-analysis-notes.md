# Python for Data Analysis 相关笔记

## 1. 高等数据知识


## 2. 线性代数知识
### 2.1 标量、向量、矩阵和张量(Scalars, Vectors, Matrices and Tensors)

* **标量**（scalar): 一个标量就是一个单独的数， 它不同于线性代数中研究的其它大部分对象（通常是多个数的数组）。用斜体表示标量，标量通常被赋予小写的变量名称。当我们介绍标量时，会明确它的数据类型。例如，在定义实数标量时，我们会说"令$s \in \Bbb R $ 表示一条线的斜率"；在定义自然数标量时，我们会说"令 $n \in \Bbb N $ 表示元素的数目"。

* **向量**(vector):一个向量是一列数。这些数是有排序的。通过次序中的索引，可以确定每个单独的数。通常赋予向量粗体的小写变量名称，比如**x**。向量中的元素可以通过带脚标的斜体表示。向量**x**的第一个元素是$x_1$，第二个元素是$x_2$，等等。我们也会注明存储在向量中的元素是什么类型。如果每个元素都属于$\Bbb R$， 并且该向量有n个元素，那么该向量属于实数集$\Bbb R$的n次笛卡尔乘积构成的集合，记为 $ \Bbb R^n$。 当需要明确表示向量中的元素是，我们会将元素排列成一个方括号包围的纵列:
    $$
    \bf x = \begin{bmatrix}
    x_1 \\
    x_2 \\
    \vdots \\
    x_n
    \end{bmatrix}
    $$
我们可以把向量看作空间中的点，每个元素是不同坐标轴上的坐标。
有时我们需要索引向量中的一些元素。在这种情况下，我们定义一个包含这些 元素索引的集合，然后将该集合写在脚标处。比如，指定 $x_1 ,x_3 和 x_6$ ，我们定义集合 S = {1, 3, 6}，然后写作 $\bf x_s$ 。我们用符号－表示集合的补集中的索引。 比如 $x_{-1}$ 表示x中除 $x_1$ 外的所有元素，$x_{-S}  $表示x中除 $x_1, x_3, x_6$外所有元素构成的向量。

* **矩阵**(matrix): 矩阵是一个二维数组，其中的每一个元素被两个索引（而非 一个）所确定。我们通常会赋予矩阵粗体的大写变量名称，比如 **A**。如果一个 实数矩阵高度为 m，宽度为 n，那么我们说 $\bf A \in \Bbb R^{m×n}$ 。我们在表示矩阵中的 元素时，通常以不加粗的斜体形式使用其名称，索引用逗号间隔。比如，$A_{1 1}$ 表示 **A** 左上的元素，$A_{m,n}$ 表示**A** 右下的元素。我们通过用 ":" 表示水平坐 标，以表示垂直坐标 i 中的所有元素。比如，$A_{i,:}$ 表示A中垂直坐标i上的一横排元素。这也被称为A的第i行（row）。同样地，$A_{ :,i}$表示A的第i列(column)。当我们需要明确表示矩阵中的元素时，我们将它们写在用方括号括起来的数组中：
  $$
  \bf x = \begin{bmatrix}
  A_{1,1}, A_{1,2} \\
  A_{2,1}, A_{2,2}
  \end{bmatrix}
  $$
有时我们需要矩阵值表达式的索引，而不是单个元素。在这种情况下，我们在表达   式后面接下标，但不必将矩阵的变量名称小写化。比如，$f(A)_{i,j}$ 表示函数 f 作用在 **A** 上输出的矩阵的第 i 行第 j 列元素。

* **张量**(tensor): 在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们称之为张量。我们使用字体**A**来表示张量"A"。张量**A**中坐标为$(i,j,k)$的元素标记为$ A _{i,j,k}$。

* **转置**(transpose): 是矩阵重要的操作之一。矩阵的转置是以对角线为轴的镜像，这条从左上角到右下角的对角线被称为**主对角线** (main diagonal)。我们将矩阵 **A**的转置表示为$A^T$，定义如下：
  $$
  (A^T)_{i,j} = A_{j, i}
  $$
  向量可以看作只有一列的矩阵。对应地，向量的转置可以看作是只有一行的矩 阵。有时，我们通过将向量元素作为行矩阵写在文本行中，然后使用转置操作将其 变为标准的列向量，来定义一个向量，比如：$ x = [x_1, x_2, x_3]^T$。
  
  标量可以看作是只有一个元素的矩阵。因此，标量的转置等于它本身，$ a = a^T$。
  
  只要矩阵的形状一样，我们可以把两个矩阵相加。两个矩阵相加是指对应位置 的元素相加，比如 C = A + B，其中 $C_{i, j}= A_{i,j} + B_{i,j}$ 。
  
  标量和矩阵相乘，或是和矩阵相加时，我们只需要将其与矩阵的每个元素相乘或者相加，比如 $ D = a \cdot B + c$，其中，$ D_{i,j} = a \cdot B_{i,j}  -c $。
  
  在深度学习中， 我们也使用一些不那么常规的符号。我们允许矩阵和向量相 加，产生另一个矩阵：$C = A + b$，其中 $C_{i,j} = A_{i,j} + b_j$ 。换言之，向量 b 和矩阵 A 的每一行相加。这个简写方法使我们无需在加法操作前定义一个将向量 b 复制 到每一行而生成的矩阵。这种隐式地复制向量 b 到很多位置的方式， 被称为广播（broadcasting）。

### 2.2 矩阵和向量相乘
两个矩阵A和B的**矩阵乘积**(matrix product)是第三个矩阵C。矩阵A的列数必须和矩阵B的行数相等。如果矩阵A的形状是 $m \times n$，矩阵B的形状是 $ n \times p $， 那么矩阵C的形状是 $ m \times p$。矩阵乘法的公式为：  
$$
  C = AB.
$$
具体乘法操作为：
$$
  C_{i, j} = \sum_k{A_{i,k}B_{k,j}}
$$
> 两个矩阵的乘积不是指两个矩阵中对应元素的乘积。不过，这样的矩阵操作确实存在，被称作**元素对应乘积**(element-wise product)或者**Hadamard乘积**(Hadamard product)，记为$ A \bigodot B$。

两个相同维数的向量x和y的**点积**（dot product）可以看作矩阵乘积$X^Ty$。可以把矩阵乘积 C=AB中计算$C_{i,j}$的步骤看作是A的第i行和B的第j列之间的点积。

矩阵乘积运算具有很多的性质,比如，矩阵乘积服从分配律：
$$
  A(B + C) = AB + AC
$$
矩阵乘积也服从结合律：
$$
  A(BC) = (AB)C
$$
矩阵乘积不满足交换律(AB = BA的情况并非总是满足)，但是，两个向量的**点积**（dot product）满足交换律：
$$
  x^Ty = y^Tx
$$
矩阵乘积的转置有如下简单的形式：
$$
  （AB）^T = B^TA^T
$$
利用两个向量点积的结果是标量，标量的转置是自身的事实，我们可以证明：
$$
  x^Ty = (x^ty)^T = y^Tx
$$
对于如下线性方程组：
$$
  Ax = b 
$$
其中，$ A \in \Bbb R^{m \times n}$是一个已知矩阵，$b \in \Bbb R^m$是一个已知向量，$x \in \Bbb R^n$是一个要求解的为止向量。向量x的每一个元素$x_i$都是未知的。矩阵A的每一行和b中对应的元素构成一个约束。我们可以把 $ Ax = b$重写为：

$$
   A_{1,:}x = b_1\\
   A_{1,:}x = b_2\\
   \cdots \\
   A_{m,:}x = b_m
$$
或者更明确地写成：
$$
  A_{1,1}x_1 + A_{1,2}x_2 + \cdots + A_{1,n}x_n = b_1 \\
  A_{2,1}x_1 + A_{2,2}x_2 + \cdots + A_{2,n}x_n = b_2 \\
  \cdots \\
  A_{m,1}x_1 + A_{m,2}x_2 + \cdots + A_{m,n}x_n = b_m \\
$$
矩阵的向量乘积符号为这种形式的方程提供了跟紧凑的表示。

下面利用python的numpy库，列举几个矩阵乘法的例子：

>矩阵乘法和矩阵相关定律

$$ {A}({B}+{C}) = {AB}+{AC} $$

$$
  A = \begin{bmatrix} 3 & 3 \\ 1 & 4 \\ 7 & 6 \end{bmatrix},
  B = \begin{bmatrix} 5 \\ 2 \end{bmatrix} ,
  C = \begin{bmatrix} 4 \\ 3 \end{bmatrix} 
$$

$$
  A(B + C) = \begin{bmatrix} 3 & 3 \\ 1 & 4 \\ 7 & 6 \end{bmatrix} \times \begin{pmatrix} \begin{bmatrix} 5 \\ 2 \end{bmatrix} +  \begin{bmatrix} 4 \\ 3 \end{bmatrix} \end{pmatrix} = \begin{bmatrix} 2 & 3\\1&4\\7&6 \end{bmatrix} \times \begin{bmatrix} 9\\5 \end{bmatrix} \\
  =  \begin{bmatrix} 2 \times 9 + 3 \times 5\\ 1\times 9 + 4 \times 5 \\ 7 \times 9 + 6 \times 5 \end{bmatrix} = \begin{bmatrix} 33\\29\\93 \end{bmatrix}
$$

等价于

$$
AB \times AC = \begin{bmatrix} 2&3\\1&4\\7&6 \end{bmatrix} \times \begin{bmatrix} 5\\2 \end{bmatrix} + \begin{bmatrix} 2&3\\1&4\\7&6 \end{bmatrix} \times \begin{bmatrix} 4\\3 \end{bmatrix} \\
= \begin{bmatrix} 2\times 5 + 3 \times 2 \\ 1 \times 5 + 4 \times 2 \\ 7 \times 5 + 6 \times 2 \end{bmatrix} + \begin{bmatrix} 2\times 4 + 3 \times 3 \\ 1 \times 4 + 4 \times 3 \\ 7 \times 4 + 6 \times 3 \end{bmatrix}\\
  =  \begin{bmatrix} 16\\13 \\47 \end{bmatrix} + \begin{bmatrix} 17\\ 16 \\46 \end{bmatrix} = \begin{bmatrix} 33\\29\\93 \end{bmatrix}
$$

对应的Python代码如下：  

```python
import numpy as np
A = np.array([[2, 3], [1, 4], [7, 6]])
B = np.array([[5], [2]])
C = np.array([[4], [3]])
# D = A(B + C)
D = A.dot(B + C)
# 等价于：D = AB + AC
D = A.dot(B) + A.dot(C)
# 矩阵转置：
C_t = C.T
```
### 单位矩阵和逆矩阵
为了描述**逆矩阵**（matrix inversion），需要先定义**单位矩阵**(identity matrix）。任意向量和单位矩阵相乘，都不会改变。记单位矩阵为$I_n$。形式上，$ I_n \in \Bbb R^{n \times n} $,
$$ \forall x \in \Bbb R^{n}, I_nx = x. $$
单位矩阵结构简单，所以沿对角线的元素都是1， 而所以其它位置的元素都是0：
$$
\begin{bmatrix} 1&0&0\\0&1&0\\0&0&1 \end{bmatrix}
$$
矩阵A的逆矩阵记作 $A^{-1}$, 满足如下条件：
$$ A^{-1}A = I_n $$
可以通过如下步骤求解：
$$
  Ax = b \\
  A^{-1}Ax=A^{-1}b \\
  I_nx=A^{-1}b
  x = A^{-1}b
$$
当逆矩阵$A^{-1}$存在时，有几种不同的算法都能找到它的闭解形式。理论上，相同的逆矩阵可用于多次求解不同向量$b$的方程。$\color{red}{然而，逆矩阵 A^{-1}主要是作为理论 工具使用的，并不会在大多数软件应用程序中实际使用。这是因为逆矩阵 \\ A^{-1}在数 字计算机上只能表现出有限的精度，有效使用向量 b的算法通常可以得到更精确的 x}$。

对应的Python代码如下：

```python
import numpy as np
np.eye(4) 

=> array([[1., 0., 0., 0.],
       [0., 1., 0., 0.],
       [0., 0., 1., 0.],
       [0., 0., 0., 1.]])
```
用python求解 $ I_nx = x$  

```python
import numpy as np
x = np.array([[2], [6], [3]])
x
xid = np.eye(x.shape[0]).dot(x)
xid
```
对于$ A^{-1}A = I_n$, 对应的python代码为：

```python
import numpy as np
A = np.array([[3, 0, 2], [2, 0, -2], [0, 1, 1]])
A_inv = np.linalg.inv()
A_bis = A_inv.dot(A)
```
求解A的逆矩阵，为计算一个非奇异的$(n \times n)$矩阵的逆，可以通过如下步骤进行

$$
1. 构造 (n \times 2n)的矩阵 （ A | I）\\
2. 用初等变换把 (A|I)化成(I|B) \\
3. 读取A_{-1} = B
$$

### 线性相关和生成子空间

## 统计学知识
### 协方差 （Covariance）
可以通俗的理解为：两个变量在变化过程中是同方向变化？还是反方向变化？同向或反向程度如何？你变大，同时我也变大，说明两个变量是同向变化的，这时协方差就是正的。你变大，同时我变小，说明两个变量是反向变化的，这时协方差就是负的。从数值来看，协方差的数值越大，两个变量同向程度也就越大。反之亦然。
> 百度百科定义：协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

期望值分别为E[X]与E[Y]的两个实随机变量X与Y之间的协方差Cov(X,Y)定义为：
$$Cov(X,Y) = E[(X - \mu_x)(Y - \mu_y)] $$
公式的简单解释：如果有两个变量X，Y，每个时刻的“X与其均值之差”乘以“Y与其均值之差”得到一个乘积，再对这每时刻的乘积求和并求出均值（其实是求“期望”）、

>参考链接 [如何通俗易懂地解释「协方差」与「相关系数」的概念](https://www.zhihu.com/question/20852004)

### 标准差 （Standard Deviation）
标准差（Standard Deviation） ，中文环境中又常称均方差，是离均差平方的算术平均数的平方根，用σ表示。在概率统计中最常使用作为统计分布程度上的测量。标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。
> 参考链接 [标准差](https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE)

$$
\sigma= \sqrt{\frac{1}{N}\sum_{i=1}^{N}{(x_i - \mu)}^2}
$$

> 其实标准差就是方差的算术平方根

###相关系数  
一般情况下，相关系数的公式为：
$$\rho = \frac{Cov(X,Y)} {\sigma_x \sigma_y}$$
就是用X、Y的协方差除以X的标准差和Y的标准差。相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差。既然是一种特殊的协方差，那它的意义如下：、

* 也可以反映两个变量变化时是同向还是反向，如果同向变化就为正，反向变化就为负
* 由于它是标准化后的协方差，因此其重要性就体现出来了：它消除了两个变量变化幅度的影响，而只是单纯地反映两个变量每单位变化时的相似程度。
>参考链接 [如何通俗易懂地解释「协方差」与「相关系数」的概念](https://www.zhihu.com/question/20852004)

以上的相关系数是通常所说的**皮尔逊相关系数**,还有其它的几个相关系数，具体参见
[统计学习--三种常见的相关系数](https://zhuanlan.zhihu.com/p/34717666)

* Pearson相关系数是在原始数据的方差和协方差基础上计算得到，所以对离群值比较敏感，它度量的是线性相关。因此，即使pearson相关系数为0，也只能说明变量之间不存在线性相关，但仍有可能存在曲线相关。

* Spearman相关系数和kendall相关系数都是建立在秩和观测值的相对大小的基础上得到，是一种更为一般性的非参数方法，对离群值的敏感度较低，因而也更具有耐受性，度量的主要是变量之间的联系。

### 线性回归
* [线性回归与最小二乘法](https://zhuanlan.zhihu.com/p/36910496)
* [ML-Note](https://github.com/yhangf/ML-NOTE)
* 


## Python相关知识
### 一些小技巧 
* 在学习代码的过程中，经常看到一段代码`np.random.seed(12345)` ，特地查了一下这段代码的作用，原来每次运行代码时设置相同的seed，则每次生成的随机数也相同，如果不设置seed，则每次生成的随机数都会不一样。关于seed()的用法：  
  **seed()** 用于指定随机数生成时所用算法开始的整数值,  
  * 如果使用相同的seed( )值，则每次生成的随即数都相同；
  * 如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同
  * 设置的seed()值仅一次有效
  * 
  例如：  
  
  ```python 
   import numpy as np
   #不使用seed
   np.random.randn(3)
   [out] > array([ 0.1876, -0.3299, -1.1928])
   np.random.randn(3)
   [out] > array([-0.2049, -0.3588,  0.6035])
   
   #使用seed
   np.random.seed(3)
   np.random.randn(3)
   [out] > array([1.7886, 0.4365, 0.0965])
   # 再次调用
   np.random.seed(3)
   np.random.randn(3)
   [out] > array([1.7886, 0.4365, 0.0965])
  ```
  显示两次结果相同

## Pandas和NumPy学习
### 资料地址：
* [NumPy教程](https://www.runoob.com/numpy/numpy-tutorial.html)  
* [Pandas中文网](https://www.pypandas.cn)
* [Python 3.7.6中文文档](https://docs.python.org/zh-cn/3.7/index.html)
* [Python Data Analysis with Pandas and Matplotlib](https://ourcodingclub.github.io/2018/04/18/pandas-python-intro.html)

### 一些基本的知识
#### one-hot编码（12章 为建模创建虚拟变量 中提到）
一句话概括：one hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。通过例子可能更容易理解这个概念。

one-hot code, 直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制，更加详细参加one_hot code（维基百科）。在机器学习中对于离散型的分类型的数据，需要对其进行数字化比如说性别这一属性，只能有男性或者女性或者其他这三种值，如何对这三个值进行数字化表达？一种简单的方式就是男性为0，女性为1，其他为2，这样做有什么问题？

使用上面简单的序列对分类值进行表示后，进行模型训练时可能会产生一个问题就是特征的因为数字值得不同影响模型的训练效果，在模型训练的过程中不同的值使得同一特征在样本中的权重可能发生变化，假如直接编码成1000，是不是比编码成1对模型的的影响更大。为了解决上述的问题，使训练过程中不受到因为分类值表示的问题对模型产生的负面影响，引入独热码对分类型的特征进行独热码编码。

2、编码过程

假如只有一个特征是离散值：

{sex：{male， female，other}}

该特征总共有3个不同的分类值，此时需要3个bit位表示该特征是什么值，对应bit位为1的位置对应原来的特征的值（一般情况下可以将原始的特征的取值进行排序，以便于后期使用），此时得到独热码为{100}男性 ，{010}女性，{001}其他

假如多个特征需要独热码编码，那么久按照上面的方法依次将每个特征的独热码拼接起来：

{sex：{male， female，other}}

{grade：{一年级， 二年级，三年级， 四年级}}

此时对于输入为{sex：male； grade： 四年级}进行独热编码，可以首先将sex按照上面的进行编码得到{100}，然后按照grade进行编码为{0001}，那么两者连接起来得到最后的独热码{1000001}；

使用one-hot编码的直接结果就是数据变稀疏；


## MatPlotLib和Seaborn学习
### 直方图(histogram)
直⽅图（histogram）是⼀种可以对值频率进⾏离散化显示的柱状图。数据点被拆分到离散的、间隔均 匀的⾯元中，绘制的是各⾯元中数据点的数量。直方图中非常重要的概念就是**bins**(X的值域被划分为不想交的连续子域，子域称作bucket或者bin，是X的数据分布的不相交的子集。bin的范围被称为宽度。通常，诸bins是等宽的).
如何确定合理的bins的值，可以利用 [Freedman-Diaconis rule](https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule) 进行计算:
$$ Bin \ width = 2\frac{IQR(x)}{\sqrt[3]{n}} $$
其中，IQR(x)是[interquartile range 数据的四分位](https://en.wikipedia.org/wiki/Interquartile_range)，n是观测样本x的数量。
> 其实就是bw <- 2 * IQR(x) / length(x)^(1/3)

### 密度图(density)
密度图，它是通过计算“可能会产⽣观测数据的连续概率分布的估计”⽽产⽣ 的。⼀般的过程是将该分布近似为⼀组核（即诸如正态分布之类的较为简单的分布）。因此，密度图 也被称作KDE（Kernel Density Estimate，核密度估计）图。
> 利用matplotlib绘制密度图例子：

```python
import pandas as pd
```


